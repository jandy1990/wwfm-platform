TIMS3311 Innovation & Entrepreneurship in Practice

**Assessment 2 — Critical Reflection & Diary Entries**

**Startup Partner:** Chatstat

**Critical Reflection Essay** (word count:1972 **)**

***Introduction: What this critical reflection/diary is about***

This WIL has allowed us to partner with Chatstat, an early-warning
wellbeing tool that analyses public social signals for families and
schools. Our team research objectives were to conduct customer discovery
strategies and provide a go-to-market validation in K–12. Through
interviews with students, parents, and educators, alongside product
sessions with the Chatstat team, I gained insight into how privacy,
trust, and a dual value proposition shape adoption. I applied Design
Thinking, Lean Startup, and Effectuation principles to move from
assumptions to evidence and reflect here on lessons, networks, key
learnings, and feedback.

***The overall WIL experience: personal lessons, highlights, and
challenges***

Working with Chatstat has transformed my understanding of innovation
from conceptual into a lived experience. A key personal lesson I’ve
taken away is that progress in our entrepreneurial setting depended less
on having the perfect plan and more on the quality of the next
conversation. Initially, I wanted to map the whole system. In practice,
however, momentum came from evidence-seeking moves such as lining up
interviews, synthesising what we heard, and returning to Chatstat (our
startup partner) with a single, testable question. This shift turned
uncertainty into weekly progress, allowing for effectuation and
affordable loss decisions grounded in evidence.

Additionally, I learned to favour one well-informed decision we can act
on each week as a team as opposed to attempt to explore every possible
pathway comprehensively. This cadence increased team momentum, reduced
reworking efforts, and built trust with Chatstat because every week
ended with evidence we could point to.

Another growth lesson was regarding my expression skills in innovation.
In the first meeting with Chatstat I deferred to my team members, and by
mid-semester I could frame the insight, state the trade-off, and propose
a direction with calm confidence. That shift came from preparing
together, but it also came from accepting that uncertainty is normal in
entrepreneurship and does not disqualify a clear recommendation. This
translated into establishing clear direction with Chatstat, which built
credibility and team cohesion.

The highlights from the WIL experience are centred on fieldwork.
Speaking directly to relevant stakeholders within the target market made
the challenge concrete. For instance, a Year 12 student explained the
sensitive nature of online exclusion, a parent described the tension
between care and privacy, and a chaplain articulated the burden schools
carry when harm surfaces too late. Those conversations reshaped how I
saw the product, not merely as technology to monitor, but as a promise
of reassurance delivered delicately.

The main difficulty was alignment. At one point we explored whether
parents should manage access to private social accounts under a school
licence. Later discussions clarified that Chatstat’s intention was to
remain public-data only and firmly non-intrusive. Navigating that shift
taught me to separate the problem we were trying to solve from my
preferred solution.

This flexibility helped me to treat negative feedback as a boundary that
can inspire better design according to partner needs, following a
similar approach to consulting practices. In retrospect, I would have
entered earlier meetings with a hypothesis-led brief instead of focusing
on ideating multiple pathways based on customer discovery insights.

***New networks built***

This project widened my professional network in ways that felt genuine
rather than transactional. Within the team, we learned to work like a
small consulting unit by dividing interviews, rotating who analysed
them, and converging on a single voice before partner sessions.
Externally, we built rapport with Chatstat’s founder, their team, and
opened conversations with educators, wellbeing support staff, parents,
and students. Those relationships were created through respectful
interviewing and careful follow-up, and they now form a realistic base
for future collaboration. The experience also allowed me to develop my
interpersonal communication skills in a professional context. I have
become more intentional about pre-briefing with teammates, more concise
in how I frame options towards stakeholders, and more attentive to the
emotions behind people’s words. As a result, our team meetings landed
clearer decisions as the experience unfolded, Chatstat felt heard and
aligned as we progressed, and our team moved faster because
misunderstandings were addressed before.

**Prior knowledge and how it evolved**

Prior to this WIL experience, my knowledge of innovation methods was
largely conceptual. I could define Design Thinking’s stages, summarise
Lean Startup’s build–measure–learn loop, and describe Effectuation’s
bird-in-hand principle. In practice, I tended to treat them as separate
playbooks. This project taught me to use them in combination and to do
so lightly.

Design Thinking helped us frame the problem in human terms and run
interviews that listened for signs, not just features, consistent with
Liedtka and Ogilvie’s emphasis on reframing. Lean Startup gave us the
discipline to translate insights into the smallest next test and to
define success as an observable behaviour, not an opinion or feeling.
Effectuation principles contributed towards our practicality. It helped
us gain momentum by starting with who we are, what we know, and whom we
know. For us, this meant inviting stakeholders into the effort and
operating within affordable loss rather than waiting for full certainty.

**New Knowledge, Insights, and Skills — Key Learnings**

Through continual reflection, consultations with our coordinator, and
progress check-ins with Chatstat, I identified gaps and refined my
practice. This shifted how I worked, how I applied the concepts, and how
I approached the team-based journey. This looked like a shift from
identifying design thinking, lean, and effectuation in hindsight, to
deliberately practicing them in my day-to-day work.

In practice, design thinking became an empathy-led wording change. For
example, this shift was evident in student interviews. Instead of asking
‘What do you like/don’t like about social media?’ we asked, ‘If you did
see something on social media that made you feel funny, worried, or even
upset, who would you talk to or ask for help?’. As a result, interviews
became richer and less defensive. Lean became a one-page hypothesis
sheet that forced the smallest test and a simple weekly pass/fail. Each
week we developed at least one hypothesis, used interviews to validate
or invalidate it, which directed us to decide whether to proceed,
iterate, or pivot.

This turned the team conversations into a productive decision-making
focus. Effectuation showed up as progress under constraint. We leaned on
the means at hand, such as our existing network to open doors and
context we couldn’t access cold. We also set an affordable-loss boundary
of ten interviews each over 3 weeks. That constraint gave us pace and
variety across students, parents, and staff, allowing us to quickly
stress-test the problem without building anything heavy. Those small
moves changed our output, including fewer debates about opinions and
more decisions anchored in behaviour. The shift also became visible in
our cadence, particularly evident in shorter cycles, alongside a growing
ability to turn uncertainty into the next experiment.

The first turning point came from Design Thinking’s empathy stance.
Early interviews with high school students, their parents, and a school
chaplain shifted my focus from content monitoring to reassurance. By
changing my tone through empathetic phrasing, the tone of the
conversations softened immediately. As abovementioned, I adapted the
phrasing of questions to be inclusive and evoke reflection on their
opinions, feelings and behaviour. To provide another example, I changed
my interview opener with students from “tell me about social media harm”
to “what feels tricky online right now?” That simple wording change
delivered richer stories about exclusion, fear of over-policing, and the
desire for a “helping hand” rather than surveillance. This taught me to
hear the meaning behind requests and to treat tone as part of the value
proposition (Liedtka & Ogilvie, 2011).

I carried that into deliverables by extracting the meanings of the
language we were recognising as patterns, such as “support, not
surveillance,” “peace of mind,” “early nudge” and continued to test
whether those phrases reduced resistance in future interviews. I used to
think empathy was a result of deploying design thinking methodologies. I
now see it as the work itself that makes any next step acceptable, an
insight I’ll carry into customer discovery in future projects and
ventures.

Lean became our weekly operating system. Each week we named one
decision, the minimum evidence needed, and the smallest test to get it.
We counted behaviour, not opinions (e.g., a parent agreeing to a
15-minute follow-up) and kept a no-build rule until a hypothesis
survived contact and validation with users. So, when Chatstat raised
privacy concerns around the school-paid, parent-licensed channel, we
logged it as measured learning and pivoted the sprint’s focus. The pivot
was redirected towards a value proposition that survived validation with
users, being “reassurance with minimal data.” That simple
build–measure–learn cadence (Ries, 2011) cut debate, created momentum,
and made weekly pivot/persevere calls straightforward. This kept me
honest with the data and direction, valuable in any role or consulting
project where decisions must be evidence-led.

The third learning came from Effectuation and changed the pace in which
I pursued next steps. I stopped waiting for the ideal sample and started
with the means at hand. I started with colleagues, who, on behalf of our
team, sent out interview requests to parents they know have children in
school. Alongside this, I initially reached out to family friends who
were undertaking school placements. This had me thinking creatively to
ask a chaplain contact who also referred me to a school basketball
coach. That crazy quilt of stakeholders expanded our reach faster than
formal recruitment would have. Equally important was affordable loss.
Instead of designing a heavy pilot, I capped each test at what we could
risk in a week. For us, that looked like testing at least 1 assumption
per week, and we each aimed to conduct at least one interview per week
to test rising assumptions. Finally, lemonade helped when our
private-access idea was ruled out. Rather than defend it, we reframed
the constraint (“public-data only”) as the core brief and tested how we
would deliver reassurance with minimal data (Sarasvathy, 2001). That
pivot preserved relationships and sharpened our design.

**Anticipated future impact**

This experience has increased my entrepreneurial confidence in a way
that feels durable. I now know how to find momentum quickly in a messy
and uncertain starting point, build an adaptable learning plan around
interviews and small tests, and consult a startup partner through
options without over-promising. The mechanics, such as writing testable
hypotheses and measuring them through observations, running ethical
interviews, synthesising quotes into insight themes, and shaping
decision pathways are repeatable. More importantly, I learned to balance
empathy when performing fieldwork. Specifically, I valued opportunities
to practice respect towards people’s opinions while still asking for the
behaviour that would validate a proposition. I can see myself applying
this approach in future roles where uncertainty and complexity is the
norm because success is anchored on how consistently one can practice
the habit of moving from assumption to evidence with care.

**What I valued most in this WIL and three suggestions for WIL
improvement**

What I valued most in this WIL was the blend of real stakeholder work
and thoughtful mentorship. The interviews provided us with grounded
substance and applying it to a thriving startup made it exciting. Each
consultation with our mentor Jack helped turn the evidence into
encouragement for next steps.

To make the experience even stronger, I would suggest adding further in
person catchups and encourage further sharing of each other’s journey as
it may reveal further fresh perspectives and raises the bar in a way
that encourages accountability across the class. Another suggestion
would be to emphasise the diary entries and consider providing a clear
structure as how to reflect in the most productive way and to encourage
even deeper and more frequent reflection alongside the consultations.
Finally, by incorporating class activities where internal discussions
are encouraged, specifically where one teammate argues for the proposed
direction, and one argues against, as it encourages efforts to surface
weak assumptions.

**References (APA)**

Liedtka, J., & Ogilvie, T. (2011). *Designing for Growth: A Design
Thinking Tool Kit for Managers*. Columbia University Press.  
Ries, E. (2011). *The Lean Startup*. Crown Business.  
Sarasvathy, S. D. (2001). Causation and effectuation: Toward a
theoretical shift from economic inevitability to entrepreneurial
contingency. *Academy of Management Review, 26*(2), 243–263.

**Reflective Diary Entries** (Word count: 945)

***Entry 1 - First stakeholder call**  *
Our first call with Chatstat felt like stepping into a live brief. I
realised quickly that my instinct to map everything would slow us down.
After the meeting I wrote a one-page note with two questions we could
actually test in the next seven days. It was a small act, but it changed
my attitude from a student preparing to a consultant creating direction
based on testable hypotheses. I also caught myself trying to market my
ideas which I was not certain about. The team encouraged me to lead a
small segment of the next session, so I prepared a proposal that framed
the trade-off and one clear decision we wanted. Doing that once made it
easier to do again, especially in the internal project team. The
learning was simple: confidence in proposals follows preparation plus a
clear hypothesis, and partners respond better to a focused choice than
to a tour of options.

***Entry 2 - Narrowing from three segments to K–12***

We started with three options: universities, corporates, and schools.
Our behaviour-based criteria were simple: who will speak to us this
week, who has a clear wellbeing owner, and where privacy/liability risks
are lowest. Schools pulled ahead fast. A chaplain and teacher-aide
opened doors. Student/parent interviews produced concrete stories.
Universities showed interest but had ownership issues and longer
procurement. After our initial proposal, **Nandan** explicitly affirmed
focusing on K–12**,** aligning partner priorities with field evidence.
We committed to schools because it aligned with Chatstat’s new ask and
offered the most promising evidence.

***Entry 3 - First interview with a student**  *
A Year 12 student described a friend being excluded from a group chat in
a way that left no trace for adults to see. It reframed monitoring for
me. We shouldn’t be looking for a single offending message but be
looking for patterns that hint at distress so that we can be the means
to the end upon early detection. I left the call more careful about
language, and the answers were richer and less defensive. It was a small
design change with a large effect. I also started jotting down exact
phrases such as “moved chats,” “don’t want to dob,” “felt off for a
week”. We plan to use them later to test whether our iteration sounds
supportive rather than intruding.

***Entry 4 - Parent perspective***  
A parent told us she wanted reassurance, not a dashboard. She said, “I
do not need to read his messages, and I know he wouldn’t want me to
either. I just want to know when I should lean in.” That became a huge
piece of evidence for our hypothesis. I learned to treat direct quotes
as pieces of evidence to design around. It also reminded me that
Chatstat’s value can be delivered as a simple, well-timed, and
empathetic nudge of support, rather than a constant feed of information.
The shift continued to lean towards an iteration of Chatstat which would
only be a simplified, helpful supplement in the safeguarding and freedom
of using online spaces for k-12.

***Entry 5 - Misalignment and reset**  *
Mid-project, we explored a parent-licensing model that implied
private-account access due to that being one of the points raised in
interviews. Later discussions clarified that Chatstat wanted to remain
public-data only and explicitly non-intrusive due to invasion of privacy
concerns as well as the current technological capabilities and
willingness to continue using their current code. Our team felt
defensive at first because we had invested time in the alternative.
After being upset briefly, I reframed the constraint as motivation to
redesign. If privacy is non-negotiable, then the craft is to deliver
peace of mind with minimal data. That reset made our work sharper and
more respectful. It also changed my meeting habit: I now ask ‘silly
questions’ and bring up constraints up-front so the team’s ideas land
inside real boundaries rather than drifting outside them.

***Entry 6 - Synthesis day**  *
During the mid-semester break, we spent our weekend turning interview
quotes into themes. Instead of grouping by stakeholder type, we grouped
by tension. For example, we categorised themes into care vs. privacy,
early signal vs. proof, school responsibility vs. family matters.
Recognising patterns from this grouping of themes made our options
clearer. I noticed how much energy is saved when there is clarity, so
much so that it’s on paper, when a team agrees on the strategic
direction before diving in. This was the first time I was genuinely
enjoying the ups and downs of a project because of how meaningful and
radically we improved.

***Entry 7 - Most recent week***

Recently, I’ve noticed how my attention and posture have shifted. Early
on I wanted the right framework and to fit a framework into each
problem. Upon reflecting, that really limited the progress and now I
know why the start was messy. I was even struggling to identify problems
because I was too focused on the frameworks. I’ve changed in that way,
now I want the next piece of evidence and will start with a single
testable hypothesis through conducting interviews as soon as possible,
as desktop research is easy compared to developing a system of
interviews, insights, and validation. That is a subtle but important
change. I also see areas for improvement to take into the final stages
of the project: to get more effective at turning interviews into
testable insights and finding hypotheses within the themes. I say this
as we are pressed for time and need to test our solution with more
fieldwork. I’m confident that the entrepreneurial skills and habits I’ve
developed will enable us as a team to cross the finish line and create
lasting value for Chatstat.
